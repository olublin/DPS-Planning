{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb783680-5a2e-4a6b-9f4c-c1cdd9a4a97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4af0b1-4d3a-4226-8ae6-13fb56a8444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in shapefile file\n",
    "all_cases = gpd.read_file(r'/Users/leahwallihan/Durham_school_planning/geospatial files/Res_Development')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196018c8-86e1-4fea-bb07-d7205af6f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# types = A_TYPE codes we want to keep\n",
    "types = ['PL_MINSP', 'PL_SSP_SM', 'PL_SSM_SM2', 'PL_CPAA', 'PL_MINPP', 'PL_MAJSP', 'PL_MAJSUP', 'PL_PPA', 'PL_MAJPP'] \n",
    "# filter that only keeps cases of specified types\n",
    "filter_cases_type = all_cases[all_cases['A_TYPE'].isin(types)]\n",
    "# status = A_STATUS codes we want to keep\n",
    "status = all_cases['A_STATUS'].unique()\n",
    "status = status[~np.isin(status, ['WITH', 'VOID','DEN','DISAP','EXP'])]\n",
    "# filter that only keeps cases of specified status\n",
    "filter_cases_status = filter_cases_type[filter_cases_type['A_STATUS'].isin(status)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6a0c14-8b09-4417-a7f4-15d053e384d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['home', 'family', 'residen', 'mixed', 'mized', 'duplex', 'apartment', ' housing', 'condo', 'dwelling', 'tenant', 'affordable', 'units', 'townhouse']\n",
    "pattern = '|'.join(keywords)\n",
    "filtered1 = filter_cases_status[filter_cases_status['A_DESCRIPT'].str.contains(pattern, case=False, na=False)]\n",
    "\n",
    "#use not pattern to avoid these words\n",
    "keywords_avoid = ['expand','storage']\n",
    "pattern_avoid = '|'.join(keywords_avoid)\n",
    "filtered2 = filtered1[~filtered1['A_DESCRIPT'].str.contains(pattern_avoid, case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ada0c3-eb13-4a76-9ca9-e97ee1c04c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter for all status dates after 2020\n",
    "filtered2['A_STATUS_D'] = pd.to_datetime(filtered2['A_STATUS_D'])\n",
    "filtered3 = filtered2[filtered2['A_STATUS_D'].dt.year>=2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7953ded9-fd70-445d-9b0f-fa600ae13c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_for_regex(term):\n",
    "    return re.sub(r'[-\\s]+', r'\\\\s*-?\\\\s*', term)\n",
    "\n",
    "def extract_units(description):\n",
    "    # Remove square footage\n",
    "    description = re.sub(\n",
    "        r'(\\d+|\\d{1,3}(,\\d{3})*)(\\s+[A-Za-z-]+){0,2}?\\s*(SF|square feet|sq\\.?\\s*ft\\.?|sqft)',\n",
    "        '', description, flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    # Housing normalization, THIS MEANS THAT IF HOUSES->HOME, S-F -> SINGLE FAMILY, ETC.\n",
    "    term_map = {\n",
    "        \"home\": \"home\", \"homes\": \"home\", \"house\": \"home\", \"houses\": \"home\",\n",
    "        \"duplex\": \"duplex\", \"duplexes\": \"duplex\",\n",
    "        \"condo\": \"condo\", \"condominium\": \"condo\", \"condominiums\": \"condo\", \"condos\": \"condo\", \n",
    "        \"apartment\": \"apartment\", \"apartments\": \"apartment\",\n",
    "        \"townhome\": \"townhouse\", \"townhomes\": \"townhouse\",\n",
    "        \"townhouse\": \"townhouse\", \"townhouses\": \"townhouse\",\n",
    "        \"town home\": \"townhouse\", \"town homes\": \"townhouse\",\n",
    "        \"town house\": \"townhouse\", \"town houses\": \"townhouse\",\n",
    "        \"multifamily\": \"multifamily\", \"multi-family\": \"multifamily\", \"multi - family\": \"multifamily\", \"multi family\": \"multifamily\",\n",
    "        \"single family\": \"single family\", \"single-family\": \"single family\", \n",
    "        \"single - family\": \"single family\", \"s-f\": \"single family\", \"s - f\": \"single family\", \"s f\": \"single family\"\n",
    "    }\n",
    "\n",
    "    # Optional leading and trailing terms\n",
    "    modifiers = [\"attached\", \"detached\"]\n",
    "    suffixes = [\"units\", \"lots\", \"homes\", \"houses\"]\n",
    "\n",
    "    # Build regex patterns\n",
    "    housing_pattern = \"|\".join([normalize_for_regex(term) for term in term_map])\n",
    "    modifier_pattern = \"|\".join(modifiers)\n",
    "    suffix_pattern = \"|\".join(suffixes)\n",
    "\n",
    "    match_pattern = rf'''\n",
    "        \\b\n",
    "        (?P<qty>\\d{{1,4}})\n",
    "        \\s+\n",
    "        (?:(?P<mod>{modifier_pattern})\\s+)?\n",
    "        (?:[A-Za-z-]+\\s+){{0,2}}?\n",
    "        (?P<type>{housing_pattern})\n",
    "        (?:\\s+(?P<suffix>{suffix_pattern}))?\n",
    "        \\b\n",
    "    '''\n",
    "\n",
    "    matches = re.finditer(match_pattern, description, flags=re.IGNORECASE | re.VERBOSE)\n",
    "    \n",
    "    result = []\n",
    "    for match in matches:\n",
    "        qty = match.group(\"qty\")\n",
    "        raw_type = match.group(\"type\")\n",
    "        raw_mod = match.group(\"mod\")\n",
    "        raw_suffix = match.group(\"suffix\")\n",
    "\n",
    "        # Normalize type\n",
    "        norm_key = re.sub(r'[-\\s]+', ' ', raw_type.lower()).strip()\n",
    "        normalized_type = term_map.get(norm_key, norm_key)\n",
    "\n",
    "        # Build output tuple\n",
    "        result.append((\n",
    "            int(qty),\n",
    "            raw_mod.lower() if raw_mod else None,\n",
    "            normalized_type,\n",
    "            raw_suffix.lower() if raw_suffix else None\n",
    "        ))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3890e253-cbd2-4937-a9c7-44b0886237c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered3['match_results'] = filtered3['A_DESCRIPT'].apply(extract_units)\n",
    "filtered3 = filtered3.to_crs('EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b473e1c5-5ac1-461e-9cb0-8fab31aa3d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column for each relevant housing type\n",
    "housing_types = ['sf_detached', 'sf_attached', 'duplex/triplex', 'multifamily', 'condo']\n",
    "for h_type in housing_types: \n",
    "    filtered3[h_type] = 0\n",
    "\n",
    "housing_type_dict = {\n",
    "        'townhouse': 'sf_attached',\n",
    "        'home': 'sf_detached', 'single family': 'sf_detached', \n",
    "        'duplex': 'duplex/triplex', \n",
    "        'apartment': 'multifamily', 'multifamily': 'multifamily', \n",
    "        'condo': 'condo'}\n",
    "      \n",
    "    \n",
    "# function to fill in housing type columns\n",
    "def fill_types(match_results):\n",
    "\n",
    "    row_data = {h_type: 0 for h_type in housing_types}\n",
    "    for group in match_results:\n",
    "        \n",
    "        quantity = int(group[0])\n",
    "        mod = group[1] if len(group) > 1 else None\n",
    "        housing = group[2] if len(group) > 2 else None\n",
    "        \n",
    "        if housing == 'single family' and mod == 'attached':\n",
    "            row_data['sf_attached'] += quantity\n",
    "        elif housing in housing_type_dict:\n",
    "            row_data[housing_type_dict[housing]] += quantity\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return pd.Series(row_data)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2a4828-b152-4a92-a2d7-813b0fec6b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered3[housing_types] = filtered3['match_results'].apply(fill_types)\n",
    "filtered3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd06db00-a525-495e-a6bb-cca85bfa301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_school_boundaries = gpd.read_file(r'/Users/leahwallihan/Durham_school_planning/geospatial files/HS_regions') \n",
    "high_school_boundaries = high_school_boundaries.to_crs('EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85850fa-9261-4831-8209-a8f1ef1d7525",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered3_with_school = filtered3.copy()\n",
    "\n",
    "for i,geometry in enumerate(high_school_boundaries['geometry']):\n",
    "    \n",
    "    in_geometry = geometry.contains(filtered3['geometry'])\n",
    "    high_school_name = high_school_boundaries.loc[i, 'region']\n",
    "\n",
    "    filtered3_with_school.loc[in_geometry, 'region'] = high_school_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f48b98-179f-4e5e-a969-c2198e7e1bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered3_with_school.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d88c07-c6e5-4e87-bd10-c9476e702f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered3_with_school.to_file('filtered3_with_school.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8125396-a159-4045-b7c7-953cbc0a9d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered3_with_school.to_file(\"resdev_cases.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352fb10a-d880-484e-85a4-a835269126c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
